---
title: "Applying Spectral Methods To Mizer"
author: "Richard Southwell"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Feeding Kernels


Let $\{1,..,s\}$ denote the set of species.

The feeding Kernel $\Phi _i$ measures amount of preference that a predator has weight $W_p$ has for a prey of weight $w$ is 

$$\Phi _i \left( \frac{w_p}{w} \right) = \exp \left[ \frac{-\left(\ln \left( \frac{w}{w_p} \right) - \ln(\beta _i ^*) \right)^2}{2\sigma_i ^2} \right].$$
We shall normalize mass by dividing by the egg size $w_0,$ and logs, to re-represent this information in the `x-space' where $x=\frac{\log(w)}{log(w_{0})},$ and $y=\frac{\log(w_p)}{log(w_{0})}.$ Before we consider the feeding kernel in these terms, let us note, that for any real number $v$ we have:

$$\Phi_{i}\left(e^{v}\right)=\exp\left[\frac{-\left(\ln\left(e^{-v}\right)-\ln(\beta_{i}^{*})\right)^{2}}{2\sigma_{i}^{2}}\right]=\exp\left[\frac{-\left(v+\beta_{i}\right)^{2}}{2\sigma_{i}^{2}}\right],
$$
where $\beta_i = \ln(\beta_i ^*),$ and $\Phi_{i}\left(e^{v}\right)$ is concentrated about $-\beta_i.$

Let us return to consideration of $\Phi _i \left( \frac{w_p}{w} \right).$ By making our substitutions, we can rewrite $Phi_i$ in terms of $x$ and $y$ as

$$\Phi_{i}\left(\frac{w_{p}}{w}\right)	=	\Phi_{i}\left(\frac{w_{0}e^{y}}{w_{0}e^{x}}\right)=\Phi_{i}(e^{y-x})=\exp\left[\frac{-\left(y-x+\beta_{i}\right)^{2}}{2\sigma_{i}^{2}}\right]$$

To illustrate, let us consider a practical example where the width of the feeding distribution is $\sigma_i = 1,$ the (log-space) predator size is $x=8$, and the log of the preferred predator-prey mass ratio is $\beta_i = \ln(\beta _i ^* ) = 3.$ 

Below we plot the resulting feeding kernel, the horizontal axis gives the (log-space) prey size, and the vertical axis measures the amount of preference that our size $x=8$ predators have for this prey:


```{r}
sigma <- 1
x <- 8
beta <- 3
dy <- 0.1
y <- seq(0, 10, by = dy)
Preference_x_has_for_prey_y <- exp((-((y-x+beta)^2))/(2*sigma^2))
plot(y,Preference_x_has_for_prey_y)
```
Because the size of the predator is $x=8,$ its most preferred prey size is 
$$x - \beta_i = 8-3$$, which is the $y$ value at which the feeding preference function plotted above is concentrated at.   

mass ratios, 

Next: add x and y in, and make plot

and 
 

The predation mortality
for a species $i$, with a size $w$ such that

\[
x=\frac{\log(w)}{log(w_{0})}
\]

In the $x$ space we want to evaluate the $\mu_{P,i}(x),$$\forall x\in[x_{0},X_{i}]$,
where $w_{0}$ is the fish size, and $X_{i}$ is the maximal size/
biomass of species $i\in{1,..,s},$ and $s$ is the number of species.

\[
\ensuremath{\mu_{P,i}(x)=\sum_{j=1}^{s}\int_{-\infty}^{\infty}\phi_{j}(y)q_{j,i}(x-y)dy}
\]

We can rewrite this expression as $\ensuremath{\mu_{P,i}(x)=\sum_{j=1}^{s}\mathbb{I}_{j,i}(x),}$where
$\mathbb{I}_{j,i}(x)=\int_{-\infty}^{\infty}\phi_{j}(y)q_{j,i}(x-y).$
Here $supp(q_{j,i})=[x_{0},X_{j}]=[0,X_{j}],$ and 



*****************************


* * * * *

## Truncated gaussian feeding kernel from mizer


We define our truncated Gaussian feeding kernel $\phi_{j}(v)$ such
that $\forall v\in\mathbb{R}$ we have 

\[
\Phi_j(e^v)= \phi_{j}(v)=\begin{cases}
\exp\left(\frac{-(v+\beta_{j})^{2}}{2\sigma_{j}^{2}}\right) & \text{if \ensuremath{v\in[-\beta_{j}-3\sigma_{j},0]}}\\
0 & \text{otherwise}
\end{cases}
\]

denotes the feeding kernel. Although in practice $\phi_{j}(v)$ is a truncated Gaussian, concentrated at
$-\beta_{j}.$ Naturally $\phi_{j}(v)\rightarrow0$ as $v\rightarrow-\beta_{j}-3\sigma_{j},$
but we also artificially the feeding kernel in mizer so that $v\geq\phi_{j}(v)\Rightarrow\phi_{j}(v)=0,$to
represent how predators will not eat prey larger than themselves.

## Mortality Integral And Spectral Methods


In order to determine $\ensuremath{\mu_{P,i}(x)=\sum_{j=1}^{s}\mathbb{I}_{j,i}(x),}$
we wish to evaluate each 

\[
\mathbb{I}_{j,i}(x)=\int_{-\infty}^{\infty}\phi_{j}(y)q_{j,i}(x-y).dy=\int_{-\beta_{j}-3\sigma_{j}}^{0}\phi_{j}(y)q_{j,i}(x-y).dy
\]

$\forall x\in[x_{0},X_{i}]=[0,X_{j}]$

where $supp(q_{j,i})=[x_{0},X_{j}]=[0,X_{j}]$

We can do this directly, using spectral methods. 

In this integral, we gave that $q_{j,i}(v)$ is used $\forall v=x-y\in[0,X_{i}+\beta_{j}+3\sigma_{j}].$
This means it makes treat $\mathbb{I}_{j,i}(x)$ is a convolution
integral, with period 

\[
P_{i,j}=length\left([-\beta_{j}-3\sigma_{j},0]\right)+length\left([0,X_{i}]\right)=X_{i}+\beta_{j}+3\sigma_{j}=P_{j,i}
\]

Suppose $\bar{\phi_{j}}(v)$ is the periodic extension of $\phi_{j}(v)$
that agrees with $\phi_{j}(v),$ for all $v\in[-\beta_{j}-3\sigma_{j},-\beta_{j}-3\sigma_{j}+P_{j,i}].$

Suppose $\overline{q_{j,i}(v)}$ is the periodic extension of $q_{j,i}(v)$
that agrees with $q_{j,i}(v),$ $\forall v\in[0,X_{i}+\beta_{j}+3\sigma_{j}]=[0,P].$

We can find the appropriate data to input into our spectral integration
method by noting that $v\in[0,P_{j,i}]\Rightarrow\overline{q_{j,i}(v)}=q_{j,i}(v)$
and 

Note that $\forall v\in[0.P]\Rightarrow\bar{\phi_{j}}(v)=\phi_{j}(v-P),$
and now we can evaluate

\[
\mathbb{I}_{j,i}(x)=\int_{-\beta_{j}-3\sigma_{j}}^{0}\phi_{j}(y)q_{j,i}(x-y).dy
\]

\[
\mathbb{I}_{j,i}(x)=\int_{-\beta_{j}-3\sigma_{j}}^{-\beta_{j}-3\sigma_{j}+P_{j,i}}\bar{\phi_{j}}(v)\overline{q_{j,i}(v)}.dy
\]

\[
\mathbb{I}_{j,i}(x)=\int_{-\beta_{j}-3\sigma_{j}}^{-\beta_{j}-3\sigma_{j}+P_{j,i}}\phi_{j}(v-P)q_{j,i}(x-y).dy
\]

\[
\mathbb{I}_{j,i}(x)=\int_{0}^{P_{j,i}}\phi_{j}(v-P)q_{j,i}(x-y).dy
\]


## Differences in notation

In the mizer vignette they write $\beta_i$. I write $\beta _i ^*$ to mean the same thing.

In the mizer vignette they write $\phi_i$. I write $\Phi _i$ to mean the same thing.





